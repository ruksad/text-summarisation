{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appraoch & Highlights Of This Notebook**\n",
    "\n",
    "Model & Training Startegy For Summarisation - T5 Small Fine Tuning Without PEFT<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T19:04:14.506819Z",
     "iopub.status.busy": "2025-10-31T19:04:14.506321Z",
     "iopub.status.idle": "2025-10-31T19:04:25.140922Z",
     "shell.execute_reply": "2025-10-31T19:04:25.140020Z",
     "shell.execute_reply.started": "2025-10-31T19:04:14.506791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-26.0.1\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=83a67aa9d7e62e9824b1ed5b56fef1be3baf031f9fa2e6834e13f290ffdf4f3b\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score, evaluate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [evaluate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed evaluate-0.4.6 rouge_score-0.1.2\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.10.0+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.25.0+cu128)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.10.0+cu128)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch) (1.3.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.24.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.10.0+cu128)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch>=1.13.0->peft) (1.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the essential libraries\n",
    "!pip install -U pip\n",
    "!pip install transformers datasets evaluate rouge_score\n",
    "!pip install torch torchvision torchaudio #--index-url https://download.pytorch.org/whl/cu121  # adjust for your CUDA/CPU\n",
    "!pip install transformers datasets peft accelerate evaluate rouge-score nltk sentencepiece\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, platform\n",
    "print(\"platform:\", platform.platform())\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"mps available:\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0+cu128\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check for CUDA (NVIDIA GPU) availability first, then MPS, then CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA available: True\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS available: True\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA available: False\")\n",
    "    print(\"MPS available: False\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T19:04:28.033182Z",
     "iopub.status.busy": "2025-10-31T19:04:28.032625Z",
     "iopub.status.idle": "2025-10-31T19:04:42.072590Z",
     "shell.execute_reply": "2025-10-31T19:04:42.071686Z",
     "shell.execute_reply.started": "2025-10-31T19:04:28.033154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 287113\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 13368\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['article', 'highlights', 'id'],\n",
      "        num_rows: 11490\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This one command downloads, splits, and structures the data\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "# https://huggingface.co/datasets/ccdv/cnn_dailymail\n",
    "\n",
    "# You will now have a 'DatasetDict' with all three splits\n",
    "print(dataset)\n",
    "\n",
    "#small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "#small_eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(200))\n",
    "\n",
    "#small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(20000))\n",
    "#small_eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(500))\n",
    "\n",
    "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(100000))\n",
    "small_eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T19:05:04.392578Z",
     "iopub.status.busy": "2025-10-31T19:05:04.391525Z",
     "iopub.status.idle": "2025-10-31T19:05:29.739587Z",
     "shell.execute_reply": "2025-10-31T19:05:29.738843Z",
     "shell.execute_reply.started": "2025-10-31T19:05:04.392541Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bd7d45ff634aac96c7098d93ed6b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4972d550a1d4a78a5d22ad402c0bfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4bd106bd5d4ca6aa58877c5ce86be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10595b9f77404ef394653245551bbe1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50a746e2b3f4c8da4bc490b258aa54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804a37f1ff44471c8025581e65dacb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aadcad29dbc4c36af5a1da6c5241991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# 1. Choose the model checkpoint\n",
    "model_checkpoint = \"t5-small\"\n",
    "\n",
    "# 2. Load the tokenizer\n",
    "# The tokenizer will turn your text into 'input_ids'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# 3. Load the model\n",
    "# T5ForConditionalGeneration is the T5 model for tasks like summarization\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T19:05:29.741124Z",
     "iopub.status.busy": "2025-10-31T19:05:29.740623Z",
     "iopub.status.idle": "2025-10-31T19:12:05.992926Z",
     "shell.execute_reply": "2025-10-31T19:12:05.992110Z",
     "shell.execute_reply.started": "2025-10-31T19:05:29.741105Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51433631e7394200b25a71e12d0605fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1468860c6a664ae085dcb91ed81dfd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The prefix tells T5 what task to perform\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    # 1. Add the prefix to all articles\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "\n",
    "    # 2. Tokenize the articles (our inputs)\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    # 3. Tokenize the highlights (our labels/targets)\n",
    "    # UPDATED: No longer using as_target_tokenizer()\n",
    "    labels= tokenizer(\n",
    "        text_target=examples[\"highlights\"],\n",
    "          max_length=128, \n",
    "          truncation=True)\n",
    "\n",
    "    # 4. Set the 'labels' for the model\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "\n",
    "# Apply this function to all splits in our dataset\n",
    "# 'batched=True' processes multiple examples at once for speed\n",
    "#tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval_dataset = small_eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T19:12:07.547206Z",
     "iopub.status.busy": "2025-10-31T19:12:07.546503Z",
     "iopub.status.idle": "2025-10-31T19:12:07.929844Z",
     "shell.execute_reply": "2025-10-31T19:12:07.929294Z",
     "shell.execute_reply.started": "2025-10-31T19:12:07.547178Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af35d6393818465dab340551a3ebff14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# Load the ROUGE metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# We need to download this for ROUGE to work\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# The function that will be called to compute metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    # 'eval_pred' gives us model predictions and the true labels\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # 1. Decode the generated IDs back to text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # 2. Decode the label IDs back to text\n",
    "    # We replace -100 (which are padding tokens)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # 3. Add newlines for ROUGE (it expects summaries to be on separate lines)\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # 4. Compute the ROUGE scores\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    # 5. Extract the 'rouge1', 'rouge2', 'rougeL' scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:15:00.941015Z",
     "iopub.status.busy": "2025-10-31T14:15:00.940816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint output_dir: /content/drive/MyDrive/text-summarization/t5_small_no_peft_upscaled/checkpoints\n",
      "Resuming training from checkpoint: /content/drive/MyDrive/text-summarization/t5_small_no_peft_upscaled/checkpoints/checkpoint-28000\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37500' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37500/37500 1:13:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>28200</td>\n",
       "      <td>1.829778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28400</td>\n",
       "      <td>1.850463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28600</td>\n",
       "      <td>1.865371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28800</td>\n",
       "      <td>1.840033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>1.822613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29200</td>\n",
       "      <td>1.820055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29400</td>\n",
       "      <td>1.838468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29600</td>\n",
       "      <td>1.828364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29800</td>\n",
       "      <td>1.858482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.835651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30200</td>\n",
       "      <td>1.844973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30400</td>\n",
       "      <td>1.855178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30600</td>\n",
       "      <td>1.872056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30800</td>\n",
       "      <td>1.857257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>1.856925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31200</td>\n",
       "      <td>1.804858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31400</td>\n",
       "      <td>1.803174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31600</td>\n",
       "      <td>1.882041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31800</td>\n",
       "      <td>1.869457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>1.834490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32200</td>\n",
       "      <td>1.836367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32400</td>\n",
       "      <td>1.857350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32600</td>\n",
       "      <td>1.820704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32800</td>\n",
       "      <td>1.826978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>1.783724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33200</td>\n",
       "      <td>1.851807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33400</td>\n",
       "      <td>1.848761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33600</td>\n",
       "      <td>1.854957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33800</td>\n",
       "      <td>1.826997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>1.838490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34200</td>\n",
       "      <td>1.835394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34400</td>\n",
       "      <td>1.818055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34600</td>\n",
       "      <td>1.843772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34800</td>\n",
       "      <td>1.822809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.837448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35200</td>\n",
       "      <td>1.825862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35400</td>\n",
       "      <td>1.836912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35600</td>\n",
       "      <td>1.831998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35800</td>\n",
       "      <td>1.827417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>1.843427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36200</td>\n",
       "      <td>1.835716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36400</td>\n",
       "      <td>1.832985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36600</td>\n",
       "      <td>1.845890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36800</td>\n",
       "      <td>1.826679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>1.852785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37200</td>\n",
       "      <td>1.828923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37400</td>\n",
       "      <td>1.851054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbed28ae29049d6884a705e3bacbe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d3fe840f6146448d0493189abfa49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7743119fb11f46f8b981fc8510e908a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9421a73ea33544d69842f3017495d502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d543b480db42ab874e4b57a38350ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b76bfa5de94cdda21b18fc0ba2f1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9755a4f6c8e4ea1a4697001b075ec1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffea1d00b87b417fbfcad458b7edf459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f438f74be9a54325a5099566d4206f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d424a723046450899fff9ce6080a93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de53edb70563458e89dee78c1ac110c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to: /content/drive/MyDrive/text-summarization/t5_small_no_peft_upscaled/final_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "# --------- Checkpointing / Resume config (Colab-safe) ---------\n",
    "# Make sure you've run the Drive mount cell before this.\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/text-summarization\"\n",
    "RUN_NAME = \"t5_small_no_peft_upscaled\"\n",
    "\n",
    "# All checkpoints will be saved under this folder on Drive\n",
    "output_dir = os.path.join(DRIVE_BASE, RUN_NAME, \"checkpoints\")\n",
    "final_model_dir = os.path.join(DRIVE_BASE, RUN_NAME, \"final_model\")\n",
    "metrics_path = os.path.join(DRIVE_BASE, RUN_NAME, \"upscaled_metrics.json\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(final_model_dir, exist_ok=True)\n",
    "print(\"Checkpoint output_dir:\", output_dir)\n",
    "\n",
    "# 1. Define the Training Arguments for the upscaled run\n",
    "training_kwargs = dict(\n",
    "    output_dir=output_dir,\n",
    "\n",
    "    # --- Critical Changes for Upscaling ---\n",
    "    eval_strategy=\"no\",                    # some versions use `evaluation_strategy` (handled below)\n",
    "    report_to=\"none\",\n",
    "    logging_steps=200,\n",
    "    # -------------------------------------\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "\n",
    "    # --- NEW: save checkpoints periodically ---\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,                        # adjust based on runtime (e.g., 500/1000/2000)\n",
    "    save_total_limit=3,\n",
    "    # -----------------------------------------\n",
    " )\n",
    "\n",
    "# Compatibility: older Transformers uses `evaluation_strategy` instead of `eval_strategy`\n",
    "try:\n",
    "    training_args = Seq2SeqTrainingArguments(**training_kwargs)\n",
    "except TypeError as e:\n",
    "    if \"eval_strategy\" in training_kwargs:\n",
    "        training_kwargs[\"evaluation_strategy\"] = training_kwargs.pop(\"eval_strategy\")\n",
    "        training_args = Seq2SeqTrainingArguments(**training_kwargs)\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# 2. Create the Data Collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# 3. Initialize the Trainer.\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    " )\n",
    "\n",
    "# 4. Start / Resume Training\n",
    "last_checkpoint = get_last_checkpoint(output_dir) if os.path.isdir(output_dir) else None\n",
    "if last_checkpoint is not None:\n",
    "    print(f\"Resuming training from checkpoint: {last_checkpoint}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train(resume_from_checkpoint=last_checkpoint)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# 5. Save your final model (also on Drive)\n",
    "trainer.save_model(final_model_dir)\n",
    "print(\"Final model saved to:\", final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data paths: ['/root/nltk_data', '/usr/nltk_data', '/usr/share/nltk_data', '/usr/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', '/content/nltk_data', '/content/nltk_data', '/content/nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /content/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Make downloads deterministic in Colab\n",
    "NLTK_DIR = \"/content/nltk_data\"\n",
    "output_dir = os.path.join(DRIVE_BASE, RUN_NAME, NLTK_DIR)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "nltk.data.path.append(output_dir)\n",
    "\n",
    "nltk.download(\"punkt\", download_dir=output_dir)\n",
    "# Newer NLTK may require this as well\n",
    "nltk.download(\"punkt_tab\", download_dir=output_dir)\n",
    "\n",
    "print(\"NLTK data paths:\", nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T13:12:27.717889Z",
     "iopub.status.busy": "2025-10-31T13:12:27.717064Z",
     "iopub.status.idle": "2025-10-31T13:13:05.739000Z",
     "shell.execute_reply": "2025-10-31T13:13:05.738215Z",
     "shell.execute_reply.started": "2025-10-31T13:12:27.717862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final evaluation on the validation examples...\n",
      "This may take several minutes as it generates summaries.\n",
      "\n",
      "--- FINAL ROUGE SCORES ---\n",
      "{'eval_loss': 1.6220036745071411, 'eval_rouge1': 25.6728, 'eval_rouge2': 12.6292, 'eval_rougeL': 21.0744, 'eval_rougeLsum': 24.1449, 'eval_runtime': 88.3245, 'eval_samples_per_second': 11.322, 'eval_steps_per_second': 1.415, 'epoch': 3.0}\n",
      "Metrics saved to: /content/drive/MyDrive/text-summarization/t5_small_no_peft_upscaled/upscaled_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# --- Run Final Evaluation ---\n",
    "\n",
    "print(\"Running final evaluation on the validation examples...\")\n",
    "print(\"This may take several minutes as it generates summaries.\")\n",
    "\n",
    "# This command tells the trainer to run the evaluation\n",
    "# on the 'eval_dataset' one time.\n",
    "metrics = trainer.evaluate()\n",
    "\n",
    "print(\"\\n--- FINAL ROUGE SCORES ---\")\n",
    "print(metrics)\n",
    "\n",
    "# Save scores to Drive (path is defined in the training cell)\n",
    "import json\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f)\n",
    "print(\"Metrics saved to:\", metrics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:05:41.369237Z",
     "iopub.status.busy": "2025-10-31T14:05:41.368932Z",
     "iopub.status.idle": "2025-10-31T14:05:45.149720Z",
     "shell.execute_reply": "2025-10-31T14:05:45.148943Z",
     "shell.execute_reply.started": "2025-10-31T14:05:41.369214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Lead-3 summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e32ff6d6523433b89cec8c113f80896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de258787140487e821c5969ce099184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LEAD-3 BASELINE ROUGE SCORES ---\n",
      "{'rouge1': np.float64(41.8318), 'rouge2': np.float64(19.3325), 'rougeL': np.float64(26.4416), 'rougeLsum': np.float64(38.1535)}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm # Shows a progress bar\n",
    "\n",
    "nltk.download('punkt') # Make sure the sentence tokenizer is downloaded\n",
    "\n",
    "# Load your (non-tokenized) eval dataset again\n",
    "eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(500))\n",
    "\n",
    "# 1. The Lead-3 Function\n",
    "def lead3_summarizer(article):\n",
    "    # Split into sentences\n",
    "    sentences = nltk.sent_tokenize(article)\n",
    "    # Get the first 3\n",
    "    lead_3 = \" \".join(sentences[:3])\n",
    "    return lead_3\n",
    "\n",
    "# 2. Get all predictions and labels\n",
    "print(\"Generating Lead-3 summaries...\")\n",
    "lead_3_predictions = [lead3_summarizer(article) for article in tqdm(eval_dataset[\"article\"])]\n",
    "human_labels = [summary for summary in tqdm(eval_dataset[\"highlights\"])]\n",
    "\n",
    "# 3. Get the ROUGE score\n",
    "# We can't use the full 'compute_metrics' function as-is \n",
    "# because it's designed for the Trainer. We'll call the metric directly.\n",
    "\n",
    "# This is the same ROUGE metric from your Step 5\n",
    "from evaluate import load\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# Prepare for ROUGE (it likes newlines between sentences)\n",
    "decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in lead_3_predictions]\n",
    "decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in human_labels]\n",
    "\n",
    "# Calculate ROUGE\n",
    "result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "result = {key: value * 100 for key, value in result.items()}\n",
    "result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "print(\"\\n--- LEAD-3 BASELINE ROUGE SCORES ---\")\n",
    "print(result)\n",
    "\n",
    "# Your T5-Small model (25.9 ROUGE-1) is now \"Baseline 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T13:39:26.995072Z",
     "iopub.status.busy": "2025-10-31T13:39:26.994346Z",
     "iopub.status.idle": "2025-10-31T13:39:28.412951Z",
     "shell.execute_reply": "2025-10-31T13:39:28.412198Z",
     "shell.execute_reply.started": "2025-10-31T13:39:26.995045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c65d8b26d64287a28b781caebda73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ORIGINAL ARTICLE ---\n",
      "In a significant advancement for artificial intelligence, researchers today announced the development of a new algorithm that can learn from vastly smaller datasets. This breakthrough, named 'Sparse Learning', could democratize AI by allowing smaller companies and individuals to build powerful models without the need for massive computational resources. The algorithm works by identifying and focusing on the most critical pieces of information, ignoring redundant data, which leads to faster training times and reduced computational cost.\n",
      "\n",
      "--- GENERATED SUMMARY ---\n",
      "'Sparse Learning' could democratize AI by allowing smaller companies and individuals to build powerful models without the need for massive computational resources.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Set the device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load your fine-tuned model and tokenizer from Drive\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/text-summarization\"\n",
    "RUN_NAME = \"t5_small_no_peft_upscaled\"\n",
    "model_path = os.path.join(DRIVE_BASE, RUN_NAME, \"final_model\")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "\n",
    "# Define a new, unseen article to summarize\n",
    "ARTICLE_TO_SUMMARIZE = (\n",
    "    \"In a significant advancement for artificial intelligence, researchers today \"\n",
    "    \"announced the development of a new algorithm that can learn from \"\n",
    "    \"vastly smaller datasets. This breakthrough, named 'Sparse Learning', \"\n",
    "    \"could democratize AI by allowing smaller companies and individuals to \"\n",
    "    \"build powerful models without the need for massive computational resources. \"\n",
    "    \"The algorithm works by identifying and focusing on the most critical \"\n",
    "    \"pieces of information, ignoring redundant data, which leads to faster \"\n",
    "    \"training times and reduced computational cost.\"\n",
    " )\n",
    "\n",
    "# Prepare the input text (add the T5 prefix)\n",
    "text = \"summarize: \" + ARTICLE_TO_SUMMARIZE\n",
    "\n",
    "# Tokenize the text and move tensors to the device\n",
    "inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=1024,\n",
    "    truncation=True,\n",
    " ).to(device)\n",
    "\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    num_beams=4,\n",
    "    max_length=150,\n",
    "    min_length=30,\n",
    "    early_stopping=True,\n",
    " )\n",
    "\n",
    "# Decode the generated IDs back to text\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n--- ORIGINAL ARTICLE ---\")\n",
    "print(ARTICLE_TO_SUMMARIZE)\n",
    "print(\"\\n--- GENERATED SUMMARY ---\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1654566,
     "sourceId": 2734496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
